#!/usr/bin/env python3

# Copyright (C) 2015
# ASTRON (Netherlands Institute for Radio Astronomy)
# P.O.Box 2, 7990 AA Dwingeloo, The Netherlands
#
# This file is part of the LOFAR software suite.
# The LOFAR software suite is free software: you can redistribute it
# and/or modify it under the terms of the GNU General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# The LOFAR software suite is distributed in the hope that it will be
# useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with the LOFAR software suite. If not, see <http://www.gnu.org/licenses/>.
#


from lofar.messaging import DEFAULT_BROKER, DEFAULT_BUSNAME
from lofar.messaging import EventMessage, ToBus
from lofar.mom.momqueryservice.momqueryrpc import MoMQueryRPC
from lofar.sas.resourceassignment.resourceassignmentservice.rpc import RADBRPC
from lofar.sas.datamanagement.storagequery.rpc import StorageQueryRPC
from lofar.lta.ingest.common.config import INGEST_NOTIFICATION_PREFIX

import logging
logger = logging.getLogger(__name__)

def autocleanup_all_finished_ingested_pipelines(do_submit_to_autocleanup: bool, exchange=DEFAULT_BUSNAME, broker=DEFAULT_BROKER):
    """
    convenience method to do a big disk cleanup.
    """
    from datetime import datetime
    if do_submit_to_autocleanup:
        logger.warning("every finished fully ingested pipeline with data on disk will be submitted to the autocleanup service!")
    else:
        logger.info("just scanning... nothing will be submitted to the autocleanup service...")

    logger.info("searching for finished fully ingested pipelines, this can take a while...")
    with MoMQueryRPC.create(exchange, broker) as momrpc, RADBRPC.create(exchange, broker) as radbrpc, \
         StorageQueryRPC.create(exchange, broker) as sqrpc, ToBus(exchange, broker) as tobus:

        otdb_ids_with_data_on_disk = sqrpc.getOtdbIdsFoundOnDisk()
        logger.debug("Found the following otdb ids with data on disk: %s", otdb_ids_with_data_on_disk)

        finished_pipelines = radbrpc.getTasks(task_type='pipeline', task_status='finished', otdb_ids=otdb_ids_with_data_on_disk)
        finished_pipeline_otdb_ids = [pipeline['otdb_id'] for pipeline in finished_pipelines if 'otdb_id' in pipeline]
        finished_pipeline_mom_ids = [pipeline['mom_id'] for pipeline in finished_pipelines if 'mom_id' in pipeline]

        for pipeline in sorted(finished_pipelines, key=lambda t: t['endtime'], reverse=False):
            otdb_id = pipeline['otdb_id']
            logger.debug("checking if finished pipeline with otdb_id %d has been fully ingested...", otdb_id)
            mom2id = pipeline.get('mom_id')
            if mom2id is None:
                continue

            dps = momrpc.getDataProducts(mom2id).get(mom2id)
            #import pprint
            #pprint.pprint(dps)

            if dps is None or len(dps) <= 0:
                logger.debug("could not find dataproducts for otdb_id=%d mom2id=%s to check if they are all ingested...", otdb_id, mom2id)
                continue
            ingestable_dps = [dp for dp in dps if dp['status'] is not None and dp['fileformat'] != 'none']
            ingested_dps = [dp for dp in ingestable_dps if dp['status'] == 'ingested']
            not_ingested_dps = [dp for dp in ingestable_dps if dp['status'] != 'ingested']
            #pprint.pprint(ingestable_dps)
            #pprint.pprint(dps)

            is_ingested = len(ingested_dps)>0 and len(ingested_dps) == len(ingestable_dps)
            is_partially_ingested = len(ingested_dps) > 0 and len(ingested_dps) < len(ingestable_dps)

            #if not is_ingested:
                #logger.info("finished pipeline with otdb_id %d was %singested. Not deleting anything for this pipeline and/or its predecessors.",
                #            otdb_id, "partially " if is_partially_ingested else "not ")
                #continue

            try:
                logger.debug("finished pipeline with otdb_id %d was fully ingested. checking diskusage...", otdb_id)
                du_result = sqrpc.getDiskUsageForOTDBId(otdb_id)
                if du_result.get('needs_update'):
                    du_result = sqrpc.getDiskUsageForOTDBId(otdb_id, force_update=True)

                if not du_result.get('found') or (du_result.get('disk_usage', 0) or 0) == 0:
                    logger.debug(du_result)
                    continue

                mom_details = momrpc.getObjectDetails(mom2id).get(mom2id)
            except Exception as e:
                logger.warning(e)
                continue

            logger.info("project %s pipeline \"%s\" with otdb_id %d finished at %s and has %s ingested and has %s (%s Bytes) on disk.",
                        mom_details.get('project_name'), mom_details.get('object_name'),
                        otdb_id, pipeline['endtime'],
                        "been fully" if is_ingested else "not been",
                        du_result.get('disk_usage_readable'), du_result.get('disk_usage'))

            if is_ingested and do_submit_to_autocleanup:
                msg = EventMessage(subject="%s.TaskFinished" % INGEST_NOTIFICATION_PREFIX,
                                   content={'type': 'MoM',
                                            'otdb_id': otdb_id,
                                            'message': 'resubmit of TaskFinished event for autocleanupservice'})
                logger.info("sending msg to %s: %s", tobus.exchange, msg)
                tobus.send(msg)

def main():
    from optparse import OptionParser

    # Check the invocation arguments
    parser = OptionParser('%prog [options]',
                          description='scan for fully ingested finished pipelines and notify the autocleanupservice to start cleaning up these pipelines and their obsolete upstream data if applicable.')
    parser.add_option('-b', '--broker', dest='broker', type='string', default=DEFAULT_BROKER,
                      help='Address of the messaging broker, default: %default')
    parser.add_option("-e", "--exchange", dest="exchange", type="string", default=DEFAULT_BUSNAME,
                      help="Name of the bus exchange on the broker, [default: %default]")
    parser.add_option('-V', '--verbose', dest='verbose', action='store_true', help='verbose logging')
    (options, args) = parser.parse_args()

    logging.basicConfig(format='%(asctime)s %(levelname)s %(message)s',
                        level=logging.DEBUG if options.verbose else logging.INFO)
    logging.getLogger("lofar").level = logging.WARNING

    do_submit_to_autocleanup = input("Do you want to submit the finished fully ingested pipelines to the autocleanup tool? y/<n>: ") == 'y'
    autocleanup_all_finished_ingested_pipelines(do_submit_to_autocleanup, options.exchange, options.broker)

if __name__ == '__main__':
    main()
